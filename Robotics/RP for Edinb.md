# Autonomous control of shore robotic charging systems based on computer vision  

**Innovations:**  
- Developed an autonomous shore-to-ship robotic charging system integrating computer vision (YOLOv5), lasers, and PLC for precise, efficient charging socket detection and alignment.  
- Demonstrated 94% accuracy in socket detection with a cost-effective, fast, and safe system for electric vessel charging.  
- Highlighted a novel application of YOLOv5 in a maritime setting, addressing real-time detection and energy transfer under varying conditions.  

**Limitations and Future Improvements:**  
- Limited testing scenarios in controlled environments; future studies should incorporate real-world and harsh maritime conditions for validation.  
- The system lacks sensor diversity; integrating LiDAR and multimodal data fusion could enhance reliability and precision.  
- Focused only on socket detection; extending to fault detection and predictive maintenance would ensure robustness.  
- Further optimization of YOLOv5 or exploration of newer detection models may improve performance and speed.

# Effect of Frame Processing Frequency on Object Identification Using MobileNetV2 Neural Network for a Mobile Robot  

**Innovations:**  
- Developed a mathematical framework to analyze the relationship between frame processing frequency, object identification speed, recognition accuracy, and system resource usage in MobileNetV2-based mobile robots.  
- Conducted experiments identifying optimal frame rates balancing speed, accuracy, and resource consumption, contributing to real-time robotic vision system optimization.  
- Demonstrated the trade-offs between higher frame rates (faster processing) and reduced recognition accuracy due to hardware limitations.  

**Limitations and Future Improvements:**  
- Testing was limited to controlled hardware and environmental conditions; further real-world testing across diverse settings is necessary.  
- The study lacks exploration of advanced optimization methods like hardware accelerators or adaptive frame rate adjustments based on task complexity.  
- Integration with complementary modalities, such as LiDAR or tactile sensors, could improve performance in dynamic environments.  
- Future work should focus on addressing the overheating and energy efficiency challenges posed by increased frame rates.


# Neural Radiance Fields in the Industrial and Robotics Domain: Applications, Research Opportunities and Use Cases  

**Innovations:**  
- Reviewed the application of Neural Radiance Fields (NeRFs) in industrial and robotics domains, emphasizing their potential to overcome limitations of traditional 3D modeling, such as high costs and reliance on human input.  
- Conducted proof-of-concept experiments, including NeRF-based video compression achieving up to 74% compression savings and D-NeRF for predictive obstacle avoidance, demonstrating their practicality in industrial scenarios.  
- Explored novel applications, such as dynamic scene reconstructions, CAD model augmentations, and SCADA system visualizations, highlighting NeRF’s adaptability and potential in diverse industrial tasks.  

**Limitations and Future Improvements:**  
- Limited testing in complex real-world scenarios; future research should address scalability and robustness in diverse industrial settings.  
- High computational cost and energy requirements for NeRF implementation necessitate optimization techniques or specialized hardware accelerators.  
- Further development is needed for dynamic NeRF variants to improve prediction accuracy and temporal coherence in rapidly changing environments.  
- Enhanced integration of NeRFs with existing industrial systems, such as CAD and SCADA, coulAutonomous control of shore robotic charging systems based on computer vision

- Limited testing scenarios in controlled environments; future studies should incorporate real-world and harsh maritime conditions for validation.

- The system lacks sensor diversity; integrating LiDAR and multimodal data fusion could enhance reliability and precision.

- Focused only on socket detection; extending to fault detection and predictive maintenance would ensure robustness.

- Further optimization of YOLOv5 or exploration of newer detection models may improve performance and speed.

  

​

# Effect of Frame Processing Frequency on Object Identification Using MobileNetV2 Neural Network for a Mobile Robot

  

Innovations:

- Developed a mathematical framework to analyze the relationship between frame processing frequency, object identification speed, recognition accuracy, and system resource usage in MobileNetV2-based mobile robots.

- Conducted experiments identifying optimal frame rates balancing speed, accuracy, and resource consumption, contributing to real-time robotic vision system optimization.

- Demonstrated the trade-offs between higher frame rates (faster processing) and reduced recognition accuracy due to hardware limitations.

  

Limitations and Future Improvements:

- Testing was limited to controlled hardware and environmental conditions; further real-world testing across diverse settings is necessary.

- The study lacks exploration of advanced optimization methods like hardware accelerators or adaptive frame rate adjustments based on task complexity.

- Integration with complementary modalities, such as LiDAR or tactile sensors, could improve performance in dynamic environments.

- Future work should focus on addressing the overheating and energy efficiency challenges posed by increased frame rates.

  

  

​

# Neural Radiance Fields in the Industrial and Robotics Domain: Applications, Research Opportunities and Use Cases

  

Innovations:

- Reviewed the application of Neural Radiance Fields (NeRFs) in industrial and robotics domains, emphasizing their potential to overcome limitations of traditional 3D modeling, such as high costs and reliance on human input.

- Conducted proof-of-concept experiments, including NeRF-based video compression achieving up to 74% compression savings and D-NeRF for predictive obstacle avoidance, demonstrating their practicality in industrial scenarios.d streamline adoption and usability.  
- Investigate advanced NeRF applications, such as semantic scene modifications and predictive simulations for better operational efficiency.


# Towards Embedding Dynamic Personas in Interactive Robots: Masquerading Animated Social Kinematic (MASK)  

**Innovations:**  
- Developed the MASK framework, enabling interactive robots to adopt dynamic personas through non-verbal cues such as gestures and facial expressions, enhancing user engagement.  
- Utilized large language models (LLMs) to automate persona-driven behavior transitions, reducing manual intervention in robot behavior design.  
- Integrated a perception engine, behavior selection engine, and action library to enable real-time, persona-infused interactions.  
- Demonstrated the ability to distinguish between personality-based and fictional character-based personas through user studies, achieving 76.7% accuracy in identifying intended characters.  

**Limitations and Future Improvements:**  
- Limited diversity in robotic actions led to repetitive behaviors during extended interactions; expanding the action library and observation space is necessary.  
- Delays in multi-user settings due to reliance on a single curiosity score; advanced turn-taking mechanisms are needed.  
- Mismatch between robotic hardware and character portrayal (e.g., physical size of robot vs. intended persona) reduced user immersion; future work could focus on tailoring hardware design to specific personas.  
- Static state machine architecture may not scale well with increased complexity; exploring alternative adaptive behavior selection methods is essential.  
# Learning to Control an Android Robot Head for Facial Animation
Works Shortcomings/Areas for Future ImprovementThe study reveals that while using facial landmarks and their pairwise distances as input to the learning algorithm improved the mapping of facial expressions from human actors onto a robot head,further investigations are needed to better align these representations between humans and robot heads.Additionally,the robot heads expressiveness is limited compared to humans,necessitating more sophisticated scaling and alignment methods.The study also encountered unexpected correlations between AUs and actuators,indicating the need for more precise detection of AUs and a deeper understanding of the hardwares capabilities.Future work could focus on refining these methods to enhance the robot heads ability to replicate human facial expressions accurately.

# Robotic Gestures,Human MoodsInvestigating Affective Responses in Public Interaction
Works Shortcomings/Areas for Future ImprovementThe study demonstrated significant influence of non-verbal cues on participants candy-taking behavior and the impact of post-candy-taking comments on emotive responses.However,the experiments scope was limited to a specific cultural context.Future work could benefit from replicating the study across varied cultural backdrops to explore how timing,gesture,and speech norms might require local calibration for optimal interaction.Additionally,the study could expand on the ethical guidelines for designing robots with norm-breaking behaviors,considering user consent,psychological impact,and ensuring benefit over harm,especially given the strong emotive reactions observed from mean robot responses.

# Comprehensive Analysis of Mobile Robot Target Tracking Technology Based on Computer Vision
Works Shortcomings/Areas for Future ImprovementThe paper provides a comprehensive analysis of mobile robot target tracking technology based on computer vision,discussing the technical background,working principle,and research status.However,it acknowledges that there is significant room for development in autonomous following robot technology to meet commercial needs,especially for following robot products based on visual guidance.Future research will need to explore more accurate methods,multi-modal information fusion,and cross-innovation with other fields to expand the application possibilities of computer vision in tracking robots.
# SpatialVLMEndowing Vision-Language Models with Spatial Reasoning Capabilities
Works Shortcomings/Areas for Future ImprovementThis paper introduces SpatialVLM,a system designed to enhance VLMsspatial reasoning capabilities through data synthesis and pre-training mechanisms.While the model shows improved performance in spatial reasoning tasks,the paper suggests that additional study of more nuanced geometric primitives could help fully ground spatial reasoning in 3D geometry,indicating a direction for future work.Additionally,the research highlights the potential of SpatialVLM in novel downstream applications like chain-of-thought spatial reasoning and robotics,suggesting further exploration in these areas.

# Text-to-Pepper-Robot PythonAnimator
Works Shortcomings/Areas for Future ImprovementThe thesis presents a Text-to-Pepper-Robot PythonAnimator,a tool designed to simplify the process of animating Pepper robots through text scripts.Despite its innovative approach,the system is limited to the Pepper robot model and does not currently support multi-robot coordination.The voice model variety is also limited,with all usable English models being female,which may restrict the diversity of performances.Future work could focus on expanding the voice model library,improving gesture and motion diversity,and adapting the system for use with different types of robots or multiple robots simultaneously.
# Inverse Kinematics Implementation Techniques in Robotics
Works Shortcomings/Areas for Future ImprovementThis review highlights the application of deep learning in solving inverse kinematics problems in robotics.While it underscores the potential of deep learning models,it also acknowledges the challenges related to the need for large and diverse training datasets,the generalization capabilities of these models,and the interpretability of deep learning predictions.Future research directions could involve developing efficient synthetic data generation methods,exploring transfer learning techniques,and enhancing the interpretability of deep learning models to improve their adoption in safety-critical applications.
# Programming Robot Animation Through Human Body Movement
Works Shortcomings/Areas for Future ImprovementThe paper introduces a system that translates human motion into robot motion for animating a humanoid Pepper robot.The prototype,while innovative,faces challenges such as the correspondence problem due to differences between human and robot body structures.Future improvements could include refining the mapping between human and robot joint positions for more accurate imitation,expanding the systems capabilities to include a wider range of motion possibilities,and developing more intuitive interfaces for users with varying levels of programming expertise.Additionally,considerations for personal data protection and the development of more user-friendly interaction design will be crucial for wider adoption.

# Interactive Design of Stylized Walking Gaits for Robotic Characters
Works Shortcomings/Areas for Future ImprovementThis research presents a system for artist-directed authoring of stylized bipedal walking gaits for robotic characters.While the system allows for real-time editing and execution on physical or simulated robots,it has limitations.The tool may not guarantee safety when authors exceed the robots capabilities,and it is currently designed for walk cycles,limiting its applicability to more complex gaits like running or skipping.Future work could involve developing online authoring tools that provide safety guarantees and expanding the systems capabilities to accommodate a broader range of gaits and acrobatic motions.Additionally,exploring the use of imitation learning for building dense,artifact-free gait libraries could enhance the systems applicability in real-world scenarios.
# BAA-NGPBundle-Adjusting Accelerated Neural Graphics Primitives
Works Shortcomings/Areas for Future ImprovementThe BAA-NGP framework offers a significant speed improvement in learning INR models for 3D scene reconstruction and camera pose estimation.However,the methods performance is influenced by the quality of the rendering baseline,suggesting that suboptimal results from the iNGP could affect BAA-NGPs outcomes.Future improvements could focus on enhancing the methods robustness,particularly in handling complex scenes with view-dependent reflections or limited feature detection.Integrating BAA-NGP into robotic systems for real-time environment modeling could also be a valuable direction for future research,expanding its application in robotics and automation.